{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련용 공통함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수가 생성되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 모델을 훈련시키고 결과를 보여주는 공통 함수\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "## 모델들\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "## 결과 측정용\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, \\\n",
    "                            explained_variance_score, classification_report\n",
    "\n",
    "# 한가지 모델을 훈련하고 결과를 출력함\n",
    "## model:   훈련시킬 모델\n",
    "## average: 평가 함수에 사용되는 average. 무슨 의미인지는 불명확, 문서를 따름\n",
    "def run_model_and_print_result(model, x_train, x_test, y_train, y_test, average):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    if isinstance(model, LogisticRegression): # 문서의 regression에 사용하는 metric중 맨 위 것을 사용. 이유는 모름\n",
    "        print('explained variance score: ', explained_variance_score(y_test, y_pred))\n",
    "    else : # regression이 아닌 모델에는 다른 3종을 출력.\n",
    "        print('accuracy score:  ', accuracy_score(y_test, y_pred))\n",
    "        print('precision score: ', precision_score(y_test, y_pred, average=average))\n",
    "        print('f1 score:        ', f1_score(y_test, y_pred, average=average))            \n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# 다섯가지 모델을 훈련하고 결과를 출력함\n",
    "## splited_data: (x_train, x_test, y_train, y_test)임.\n",
    "##               순서에 주의할 것\n",
    "## average:      평가 함수에 사용되는 average. 무슨 의미인지는 불명확, 문서를 따름\n",
    "def run_five_models_and_print_result(splited_data, average='macro'):\n",
    "    print('## LEARNING START')\n",
    "    print('')\n",
    "    \n",
    "    print('## Decision Tree ##')\n",
    "    run_model_and_print_result(DecisionTreeClassifier(), *splited_data, average)\n",
    "    print('')\n",
    "    \n",
    "    print('## Random Forest ##')\n",
    "    run_model_and_print_result(RandomForestClassifier(), *splited_data, average)\n",
    "    print('')\n",
    "    \n",
    "    print('## Support Vector Machine ##')\n",
    "    run_model_and_print_result(SVC(), *splited_data, average)\n",
    "    print('')\n",
    "    \n",
    "    print('## Stochastic Gradient Descent ##')\n",
    "    run_model_and_print_result(SGDClassifier(), *splited_data, average)\n",
    "    print('')\n",
    "    \n",
    "    print('## Logistic Regression ##')\n",
    "    run_model_and_print_result(LogisticRegression(max_iter=5000), *splited_data, average)\n",
    "    print('')\n",
    "    \n",
    "    print('## END ##')\n",
    "    \n",
    "print('함수가 생성되었습니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래에 사용될 모델 학습을 함수로 만들었다.  \n",
    "   \n",
    "Regression에는 평가 방법을 다르게 사용해야 한다는 이야기가 있어, 문서에 나온 것 중 첫번째를 사용하였다.   \n",
    "그러나 왜인지 이론적인 내용을 모른다.   \n",
    "참고한 문서: https://scikit-learn.org/stable/modules/model_evaluation.html   \n",
    "   \n",
    "나머지 모델에 대해서는 중요하다고 생각한 평가 지표 3가지를 나타내었다.   \n",
    "accuracy score: TP, TN의 평가   \n",
    "precision score: TP, FP의 평가   \n",
    "f1 score: FP, FN의 평가   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Target Names ## \n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "## 데이터 톺아보기 ##\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## LEARNING START\n",
      "\n",
      "## Decision Tree ##\n",
      "accuracy score:   0.8583333333333333\n",
      "precision score:  0.8641517550760026\n",
      "f1 score:         0.8610784983369782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.81      0.83      0.82        42\n",
      "           2       0.79      0.85      0.82        40\n",
      "           3       0.91      0.91      0.91        34\n",
      "           4       0.80      0.95      0.86        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.93      0.79      0.85        33\n",
      "           8       0.82      0.65      0.73        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n",
      "\n",
      "## Random Forest ##\n",
      "accuracy score:   0.9638888888888889\n",
      "precision score:  0.9640322948132795\n",
      "f1 score:         0.963952232694037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      0.97      0.99        40\n",
      "           3       0.97      1.00      0.99        34\n",
      "           4       0.90      0.97      0.94        37\n",
      "           5       0.90      1.00      0.95        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.97      0.86      0.91        43\n",
      "           9       0.97      0.94      0.95        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.97      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "\n",
      "## Support Vector Machine ##\n",
      "accuracy score:   0.9888888888888889\n",
      "precision score:  0.9887878787878789\n",
      "f1 score:         0.9890243833239554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "## Stochastic Gradient Descent ##\n",
      "accuracy score:   0.95\n",
      "precision score:  0.9522356990344795\n",
      "f1 score:         0.9512544142869379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.84      0.90      0.87        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.96      0.96      0.96        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.93      0.86      0.89        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "\n",
      "## Logistic Regression ##\n",
      "explained variance score:  0.8699646388043567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "\n",
      "## END ##\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "## 데이터용\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "## 그림그리기\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 글씨 데이터 불러오기\n",
    "loaded_digits = load_digits()\n",
    "\n",
    "# 사용할 이미지 데이터와 라벨\n",
    "raw_datum = loaded_digits.data\n",
    "raw_labels = loaded_digits.target\n",
    "print('## Target Names ## ')\n",
    "print(loaded_digits.target_names)\n",
    "print('')\n",
    "\n",
    "print('## 데이터 톺아보기 ##')\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(raw_datum[i].reshape(8,8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('')\n",
    "\n",
    "# 데이터를 훈련용과 테스트용으로 나눔\n",
    "splited_data = train_test_split(raw_datum, raw_labels, test_size=0.2, random_state=7)\n",
    "\n",
    "# 다섯가지 모델을 훈련시키고 결과를 출력함\n",
    "run_five_models_and_print_result(splited_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 평가 지표가 비슷하게 나온 가운데 Regression의 평가 점수는 좋지 않다.  \n",
    "하지만 실제 Regression으로 나온 결과를 보면 그다지 나쁘지 않은데, 연속적인 값을 예측하는 평가 지표를 사용하였기 때문이 아닐까 추측된다.  \n",
    "맞는 값에서도 점수 하락이 발생하게 된 것이 아닌가 추측. 이론적인 부분을 몰라 알 수 없다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터를 표로 보여주는 공통함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수가 생성되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 보여주는 공통 함수\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 표 형태로 나타냄\n",
    "def describe_data_with_data_frame(data, columns, labels):\n",
    "    data_frame = pd.DataFrame(data=data, columns=columns)\n",
    "    data_frame['label'] = labels\n",
    "    print(data_frame)\n",
    "    \n",
    "print('함수가 생성되었습니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 함수는 아래에 데이터를 표로 보여주기 위해 만들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Target Names ## \n",
      "['class_0' 'class_1' 'class_2']\n",
      "\n",
      "## 데이터 톺아보기 ##\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  label  \n",
      "0                            3.92   1065.0      0  \n",
      "1                            3.40   1050.0      0  \n",
      "2                            3.17   1185.0      0  \n",
      "3                            3.45   1480.0      0  \n",
      "4                            2.93    735.0      0  \n",
      "..                            ...      ...    ...  \n",
      "173                          1.74    740.0      2  \n",
      "174                          1.56    750.0      2  \n",
      "175                          1.56    835.0      2  \n",
      "176                          1.62    840.0      2  \n",
      "177                          1.60    560.0      2  \n",
      "\n",
      "[178 rows x 14 columns]\n",
      "\n",
      "## LEARNING START\n",
      "\n",
      "## Decision Tree ##\n",
      "accuracy score:   0.8888888888888888\n",
      "precision score:  0.9095238095238095\n",
      "f1 score:         0.8869047619047619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.80      0.92      0.86        13\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.91      0.88      0.89        36\n",
      "weighted avg       0.90      0.89      0.89        36\n",
      "\n",
      "\n",
      "## Random Forest ##\n",
      "accuracy score:   0.9722222222222222\n",
      "precision score:  0.9777777777777779\n",
      "f1 score:         0.9751724137931035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "\n",
      "## Support Vector Machine ##\n",
      "accuracy score:   0.6388888888888888\n",
      "precision score:  0.565204678362573\n",
      "f1 score:         0.5588369963369964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85        14\n",
      "           1       0.58      0.85      0.69        13\n",
      "           2       0.20      0.11      0.14         9\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.57      0.58      0.56        36\n",
      "weighted avg       0.62      0.64      0.61        36\n",
      "\n",
      "\n",
      "## Stochastic Gradient Descent ##\n",
      "accuracy score:   0.7222222222222222\n",
      "precision score:  0.8550724637681159\n",
      "f1 score:         0.6150997150997151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        14\n",
      "           1       0.57      1.00      0.72        13\n",
      "           2       1.00      0.11      0.20         9\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.86      0.66      0.62        36\n",
      "weighted avg       0.84      0.72      0.67        36\n",
      "\n",
      "\n",
      "## Logistic Regression ##\n",
      "explained variance score:  0.9153175591531756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       0.92      0.92      0.92        13\n",
      "           2       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.94      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "## END ##\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 와인 데이터 불러오기\n",
    "loaded_wines = load_wine()\n",
    "\n",
    "# 사용할 이미지 데이터와 라벨\n",
    "raw_datum = loaded_wines.data\n",
    "raw_labels = loaded_wines.target\n",
    "print('## Target Names ## ')\n",
    "print(loaded_wines.target_names)\n",
    "print('')\n",
    "\n",
    "print('## 데이터 톺아보기 ##')\n",
    "describe_data_with_data_frame(raw_datum, loaded_wines.feature_names, raw_labels)\n",
    "print('')\n",
    "\n",
    "# 데이터를 훈련용과 테스트용으로 나눔\n",
    "splited_data = train_test_split(raw_datum, raw_labels, test_size=0.2, random_state=1)\n",
    "\n",
    "# 다섯가지 모델을 훈련시키고 결과를 출력함\n",
    "run_five_models_and_print_result(splited_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 모델 평가 지표들은 비슷하게 나온 가운데, 모델마다 평가 점수에 차이가 많다\n",
    "SVM, SGD가 많이 저조하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Target Names ## \n",
      "['malignant' 'benign']\n",
      "\n",
      "## 데이터 톺아보기 ##\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
      "0                  0.2654          0.4601                  0.11890      0  \n",
      "1                  0.1860          0.2750                  0.08902      0  \n",
      "2                  0.2430          0.3613                  0.08758      0  \n",
      "3                  0.2575          0.6638                  0.17300      0  \n",
      "4                  0.1625          0.2364                  0.07678      0  \n",
      "..                    ...             ...                      ...    ...  \n",
      "564                0.2216          0.2060                  0.07115      0  \n",
      "565                0.1628          0.2572                  0.06637      0  \n",
      "566                0.1418          0.2218                  0.07820      0  \n",
      "567                0.2650          0.4087                  0.12400      0  \n",
      "568                0.0000          0.2871                  0.07039      1  \n",
      "\n",
      "[569 rows x 31 columns]\n",
      "\n",
      "## LEARNING START\n",
      "\n",
      "## Decision Tree ##\n",
      "accuracy score:   0.9035087719298246\n",
      "precision score:  0.8987341772151899\n",
      "f1 score:         0.9281045751633986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85        40\n",
      "           1       0.90      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.91      0.88      0.89       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "\n",
      "## Random Forest ##\n",
      "accuracy score:   0.9649122807017544\n",
      "precision score:  0.9487179487179487\n",
      "f1 score:         0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        40\n",
      "           1       0.95      1.00      0.97        74\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.95      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "\n",
      "## Support Vector Machine ##\n",
      "accuracy score:   0.9035087719298246\n",
      "precision score:  0.8705882352941177\n",
      "f1 score:         0.9308176100628931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "\n",
      "## Stochastic Gradient Descent ##\n",
      "accuracy score:   0.9035087719298246\n",
      "precision score:  0.8888888888888888\n",
      "f1 score:         0.9290322580645162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85        40\n",
      "           1       0.89      0.97      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.91      0.87      0.89       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "\n",
      "## Logistic Regression ##\n",
      "explained variance score:  0.7810810810810811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "\n",
      "## END ##\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 유방암 데이터 불러오기\n",
    "loaded_cancers = load_breast_cancer()\n",
    "\n",
    "# 사용할 이미지 데이터와 라벨\n",
    "raw_datum = loaded_cancers.data\n",
    "raw_labels = loaded_cancers.target\n",
    "print('## Target Names ## ')\n",
    "print(loaded_cancers.target_names)\n",
    "print('')\n",
    "\n",
    "print('## 데이터 톺아보기 ##')\n",
    "describe_data_with_data_frame(raw_datum, loaded_cancers.feature_names, raw_labels)\n",
    "print('')\n",
    "\n",
    "# 데이터를 훈련용과 테스트용으로 나눔\n",
    "splited_data = train_test_split(raw_datum, raw_labels, test_size=0.2, random_state=7)\n",
    "\n",
    "# 다섯가지 모델을 훈련시키고 결과를 출력함\n",
    "## label이 두가지이므로 결과 측정에 binary 사용 => 어떤 영향이 있는지는 불명확, 단순히 문서를 따름\n",
    "run_five_models_and_print_result(splited_data, average='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질병과 관련되었으므로 양성의 검출이 더 중요하다.   \n",
    "그러므로 f1 score가 더 중요한 판단 요소가 되고, random forest가 가장 좋은 결과를 보였다.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
